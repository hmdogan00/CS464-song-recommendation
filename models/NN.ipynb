{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d0e8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilkek\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\sklearn\\utils\\validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import random\n",
    "from packaging import version\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a795654",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neurons = 9\n",
    "output_neurons = 4\n",
    "hidden_neurons= 6\n",
    "hidden_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "221287c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setting device as GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "977c5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layer):\n",
    "    if type(layer) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(layer.weight)\n",
    "        layer.bias.data.fill_(0.01)\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.build_architecture()\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def build_architecture(self):\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(input_neurons, hidden_neurons),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_neurons, output_neurons)\n",
    "        )\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear( output_neurons, hidden_neurons),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_neurons, input_neurons),\n",
    "        )\n",
    " \n",
    "    def forward(self, batch: torch.tensor):\n",
    "        return self.decode(self.encode(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a197250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a504a72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176774, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load Training and Test data\n",
    "location = os.path.join('', './data/SpotifyFeatures.csv')\n",
    "  \n",
    "data = pd.read_csv(location)\n",
    "data = data.drop_duplicates(subset=['track_id'])\n",
    "data = data[data['track_id'] != id]\n",
    "\n",
    "features_used = data[[\"genre\",\"artist_name\",\"track_name\",\"track_id\", \"acousticness\", \"danceability\",\"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"tempo\", \"valence\"]]\n",
    "\n",
    "original_data_all = np.array(features_used.values)\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(original_data_all)\n",
    "\n",
    "original_data1 = original_data_all[:,4:]\n",
    "print(original_data1.shape)\n",
    "original_data = np.array(original_data1,\"float64\")\n",
    "\n",
    "train_data = original_data[:176771,:]\n",
    "test_data = original_data[176771:,:]\n",
    "train_torch = torch.from_numpy(train_data)\n",
    "test_torch = torch.from_numpy(test_data)\n",
    "\n",
    "#Dataloader\n",
    "train_loader = DataLoader(dataset= train_torch, batch_size = batch_size)\n",
    "test_loader = DataLoader(dataset= test_torch, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13d021e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "model = Autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff0625dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f56816df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 1: 1352.198947747721\n",
      "Loss of epoch 2: 950.3281499177185\n",
      "Loss of epoch 3: 642.1350418847409\n",
      "Loss of epoch 4: 409.8792700227343\n",
      "Loss of epoch 5: 249.8308811263679\n",
      "Loss of epoch 6: 156.83438674203305\n",
      "Loss of epoch 7: 119.70563349963702\n",
      "Loss of epoch 8: 113.76228884083613\n",
      "Loss of epoch 9: 113.64307720558479\n",
      "Loss of epoch 10: 113.64301506730037\n",
      "Loss of epoch 11: 78.09483003081337\n",
      "Loss of epoch 12: 28.013788264685683\n",
      "Loss of epoch 13: 12.735679759782508\n",
      "Loss of epoch 14: 6.873497602346795\n",
      "Loss of epoch 15: 5.283136257174392\n",
      "Loss of epoch 16: 4.767644551626116\n",
      "Loss of epoch 17: 4.563745536926731\n",
      "Loss of epoch 18: 4.471057010741067\n",
      "Loss of epoch 19: 4.417368678178556\n",
      "Loss of epoch 20: 4.379208972908818\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device=device)\n",
    "            labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch.float())\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Loss of epoch {epoch + 1}: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b468a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c1969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
